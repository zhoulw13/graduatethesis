\chapter{引言}
\label{cha:1-intro}

\section{课题背景、目的和意义}
\label{sec:1-intro}

  黑白图像着色是个由来已久且研究得较为成熟的课题，这个课题的任务是将输入的黑白图
  像还原出它的色彩信息，是图形学领域的一个经典问题。在深度学习普及之前，普遍使用
  的方法是通过人为指定一些局部颜色信息，然后用最优化的方法补全颜色。而最近几年随
  着深度学习的广泛应用，许多研究也用深度学习的方法在黑白图像着色问题上做到了自动
  化，而不需要人工干涉，得到的结果也非常不错。

  传统的非深度学习方法例如~\inlinecite{journals/tog/LevinLW04}，通过人工输入一些区域的彩色条带，根据全图的灰度信息来最优化填充剩余位置的颜色信息。而深度学习的方法例如~\inlinecite{IizukaSIGGRAPH2016}、~\inlinecite{zhang2016colorful}均是通过训练神经网络的方式来进行自动上色。~\inlinecite{IizukaSIGGRAPH2016}训练了一个多层次的CNN，结合提取的局部特征与全局信息来对整张图着色。~\inlinecite{zhang2016colorful}使用的是单层次的CNN，但选择了特别的损失函数：考虑到使用欧式距离作为损失函数会使得神经网络将训练集中见过的一类物体所有可能颜色的平均值作为这类物体着色的输出，从而得到失真、灰褐色的结果。所以他们的网络对图片的每个像素输出一个所有颜色离散化后的概率分布，然后从整张图的颜色概率分布中得出一个空间连续的结果。

  然而，虽然黑白图像着色的问题已经研究得比较成熟了，但关于这个问题在时间维度的扩展问题——即黑白视频着色的研究却甚少，现在还没有全自动的黑白视频着色方法。~\inlinecite{journals/tog/LevinLW04}中除了用人工输入结合最优化的方法对黑白图像着色进行了处理，还将最优化的目标通过光流扩展到了时间维度，处理了黑白视频着色，取得了不错的结果。但是在深度学习火热的今天，还没有人提出全自动的方法来处理黑白视频着色问题。

  本文对黑白视频着色问题进行了研究，尝试通过深度学习的提出一个不需要人工干预的全自动的方法来解决这个问题。

\section{主要工作与创新}
\label{sec:1-works}

  本文的主要工作是为黑白视频着色问题提供一个全自动的解决方案，填补当前这个问题上的空白。

\subsection{图像着色}
\label{sec:1-image-color}

  在直接进行视频着色前，为了验证所选模型的可行性，先构建了一个处理2D图像的网络模型在图像数据集上训练验证。

  本文选择的深度网络模型是GAN（生成对抗网络）。该模型的思想为同时训练两个模型，生成器和判别器，训练过程中本文将黑白图像输入给生成器，期望它输出理想的着色结果即彩色图像，然后会将生成器生成的假的彩色图像与真实的彩色图像混在一起交给判别器，期望判别器能分辨出哪些是真的彩色图像，哪些是生成器生成的图像，这样两个网络之间就存在一种对抗关系：生成器要不断学习骗过判别器，而判别器也要学习将真假图像分辨出来。这样当两个网络不断迭代，到判别器也很难分辨出假的生成图像后，训练好的生成器就能拿来做图像生成了。

\subsection{视频着色}
\label{sec:1-video-color}

  在图像着色的问题上验证好了网络的可行性后，便可将生成对抗网络从处理2D图像扩展到3D视频。具体做法是将生成器与判别器两个网络的卷积核，都在原来处理二维图像的基础上添加新的一维，即是做三维的卷积，使得网络每一层都是对多帧多通道图像做处理，从而达到视频处理的目的。

  在这里，本文尝试过将整个视频每一个连续帧都放进网络做训练，后来发现这样会有几个问题：每个视频的帧数是不一样的，而网络在做卷积的三个维度（宽，高，帧数）上都是固定的，这样只能将视频分为几个帧数固定的段，分别通过网络着色后再合并，而这样又引出了段间合并的连续性问题；另外将网络从2D扩展到3D后，网络参数出现了很大的增长，如果使用连续帧的话，这个问题更加明显，后果就是网络训练变得非常慢，而训练效果也很不理想。

  基于以上的原因，本文采取了关键帧着色的方式，即对于待着色视频，按某种方式取出一定帧数的关键帧，用网络将这部分关键帧着色后，再以最优化的方式给关键帧之间的图像着色。

\subsection{帧间处理}
\label{sec:1-interframes}

  在得到关键帧的着色后，就要对关键帧之间未着色的图像进行着色，着色的依据便是已有的关键帧颜色。

  对于两个关键帧之间的黑白帧，本文采取递推的方式着色，用前一帧作为后一帧测参考来给后一帧着色，后一帧着色后又可以作为它的后一帧的参考，以此类推。在两个相邻帧之间的着色过程如下：计算两帧之间的光流，对于后一帧的每个像素，在前一帧的光流对应点附近以及与它同坐标位置的点附近，找一个灰度最接近的点，取这个点的颜色作为待着色点的颜色。这样处理后必定会有许多不正常的颜色点，所以后续还需要一些颜色修正以及帧间灰度连贯性的处理。

\subsection{数据集的选择}
\label{sec:1-dataset}

  在图像着色上，本文使用了小容量的LSUN、CIFAR10以及大容量的Image-Net数据集；在视频着色上，本文使用了UCF11和UCF101等用于动作识别的数据集。

\section{论文的组织与安排}
\label{sec:1-org}

  本文的其他章节安排如下：

  第二章介绍了本文的相关工作和预备知识，包括卷积神经网络与生成对抗网络的概念。

  第三章介绍了本文的算法，包括黑白图像着色网络（判别器网络和生成器网络，以及相关训练参数）、黑白视频着色网络以及相关训练参数和关键帧的空间平滑与时间平滑的算法，以及非关键帧的着色算法。最后展示了本文的实验结果，分析了实验结果好的原因，也对坏的结果做了分析。

  第四章总结了本文的工作，并且对未来的工作做了进一步规划。